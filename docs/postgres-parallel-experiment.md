# Эксперимент: Postgres и параллельная индексация

**Период:** 2026-02  
**Статус:** эксперимент завершён, решение — не внедрять в продуктив.

---

## Цель

Ускорить индексацию и заложить основу для сценария «общий индекс на несколько процессов» за счёт:

1. **Бекенда PostgreSQL** — альтернатива SQLite, один индекс на общую БД.
2. **Параллельной индексации** — разбиение списка файлов на сегменты и их одновременная обработка (read + AST chunking + запись в БД) при использовании Postgres.

---

## Что сделали

- **Абстракция хранилища** — интерфейс `PersistentChunkStorage`, реализации SQLite (`PersistentStorage`) и Postgres (`PostgresPersistentStorage`), фабрика по конфигу.
- **Postgres-схема и миграции** — таблицы `files`, `chunks`, `document_vectors`, `idf_scores` в pg, Drizzle (pg-core).
- **Параллельные сегменты** — при `indexingConcurrency > 1` и бекенде Postgres файлы делятся на N сегментов, каждый обрабатывается в своём «потоке» (read → chunkCodeByAST → storeFiles → storeManyChunks → storeManyChunkVectors).
- **Bulk insert чанков** — вместо поштучного `INSERT ... RETURNING id` вставка батчами (Postgres ~400 строк, SQLite ~150 из-за лимита биндов), сбор id и разнесение по файлам по `countsPerFile`.
- **Пул соединений** — опция `poolMin` и прогрев пула (несколько `SELECT 1`) при старте, чтобы при c=4 не ждать создания коннектов.
- **Замеры** — при `MEASURE_PG=1` логирование времени операций storeFiles/storeManyChunks/storeManyChunkVectors и состояния пула (total, idle, waiting).

После фиксации выводов код Postgres и связанные изменения откатили; в репозитории остаётся только SQLite-реализация.

---

## Бенчмарки (1495 файлов, 6317 чанков)

| Режим              | Время   | Память (RSS max) | CPU   |
|--------------------|--------|-------------------|-------|
| SQLite c=1         | **~41 s** | ~130 MB           | ~100% |
| Postgres c=1       | **~55 s** | ~2.3–2.6 GB       | ~76%  |
| Postgres c=4       | **~47–48 s** | ~3.0–3.2 GB   | ~87%  |

Выводы по замерам:

- **SQLite быстрее** при одном процессе: меньше накладных расходов (локальный файл, без сети).
- **Postgres c=4** даёт выигрыш по времени относительно Postgres c=1 (~8 s), но **всё равно медленнее SQLite** на 6–7 s и требует в разы больше памяти.
- Узкое место при c=4 — не создание коннектов (после прогрева пула их хватает), а **конкуренция за одни таблицы**: блокировки при параллельных INSERT/UPDATE в `chunks`, `document_vectors`, обновлении `token_count`. Самые долгие операции — `storeManyChunkVectors` (десятки тысяч строк на сегмент).

---

## Выводы

1. **Для одной машины и одного процесса** SQLite остаётся оптимальным по скорости и простоте. Переход на Postgres не даёт выигрыша по времени, только рост сложности и потребления памяти.

2. **Postgres имеет смысл**, когда нужен **общий индекс**: несколько воркеров/сервисов, один индекс в общей БД, репликация, централизованные бэкапы. Тогда выигрыш — в архитектуре, а не в скорости одного прогона индексации.

3. **Дальнейшее ускорение Postgres** (отдельные таблицы/схемы по сегментам с последующим слиянием, батчевые/асинхронные обновления) могло бы приблизить время к SQLite или чуть обогнать, но при высокой сложности реализации и поддержки. Решили, что окупаемость сомнительна.

4. **Bulk insert чанков** — полезная оптимизация сама по себе (меньше круг-трипов к БД). Её можно сохранить только в SQLite-ветке без внедрения Postgres.

---

## Решение

**Не внедрять** бекенд Postgres и параллельную индексацию в текущем виде. Оставить в качестве ориентира только SQLite и документировать сценарии (один процесс / общий индекс). Идеи из эксперимента зафиксированы в ROADMAP как «не делаем» со ссылкой на этот документ.

---

*Документ создан по итогам эксперимента, февраль 2026.*
